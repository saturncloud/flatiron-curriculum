{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction  \n",
    "In this lab, we would like to make an XGBoost model to study the e-commerce behavior from a multi-category store. First, we need to download the data to your local machine, then we will load the data into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Apply XGBoost to an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accept the kaggle policy and download the data from here https://www.kaggle.com/code/tshephisho/ecommerce-behaviour-using-xgboost/data\n",
    "- For the first model building, we'll only use the 2019-Nov csv data (which is still around ~2gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import squarify\n",
    "import matplotlib.dates as dates\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# fill this in with your path (absolute path works as well)\n",
    "path_to_file = \"../archive/2019-Nov.csv\"\n",
    "df = pd.read_csv(path_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some exploratory analysis on the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a quick look of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Know your Customers\n",
    "How many unique customers visit the site?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitor = df['user_id'].nunique()\n",
    "print (\"visitors: {}\".format(visitor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visitors Daily Trend\n",
    "Does traffic fluctuate by date? Try using the `event_time` and `user_id` to see traffic, and construct the plots for visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df.loc[:, ['event_time','user_id']]\n",
    "d['event_time'] = d['event_time'].apply(lambda s: str(s)[0:10])\n",
    "visitor_by_date = d.drop_duplicates().groupby(['event_time'])['user_id'].agg(['count'])\\\n",
    "    .sort_values(by=['event_time'], ascending=True)\n",
    "x = pd.Series(visitor_by_date.index.values).apply(lambda s: datetime.strptime(s, '%Y-%m-%d').date())\n",
    "y = visitor_by_date['count']\n",
    "plt.rcParams['figure.figsize'] = (20, 8)\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Category and Product\n",
    "With which category do customers interact the most? What brand do they view the most? You can choose just the categories with at least 30 records in order to construct the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_category_num = 30\n",
    "top_category = df.loc[:, 'category_code'].value_counts()[:max_category_num].sort_values(ascending=False)\n",
    "plt.bar(height=top_category, x=top_category.index.array,\n",
    "              color=[\"red\",\"cyan\",\"green\",\"orange\",\"blue\",\"grey\"], alpha=0.7)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When the event_type is \"purchase\", what item do customers buy?\n",
    "\n",
    "Try using `'event_type' == 'purchase'` and drop empty rows to assess which categories customers buy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What brands do the customers buy?\n",
    "Try grouping by brand and sorting the values by the brand name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del d # free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling: predict at the time of addition to a shopping cart if the user will purchase a given product or not\n",
    "\n",
    "### Feature engineering\n",
    "\n",
    "The goal of this modeling is to predict if the user will purchase a product or not when they add the product to the cart. This is called `cart abandonment` if the user does not purchase.\n",
    "\n",
    "First, reconstruct and restructure the data to feed into the machine learning model. For this use case, target only the data for which customers have \"put\" the product into the cart. The relevant `event_type`s are thus \"cart\" and \"purchase\".\n",
    "\n",
    "Create these new features in the training data set:\n",
    "- `category_level1`: category\n",
    "- `category_level2`: sub-category --> split on the \".\" in the category name\n",
    "- `weekday`: weekday of the event --> convert `event_time` to a datetime object, then use `pandas.Timestamp.weekday`\n",
    "- `activity_count`: number of activity in that session\n",
    "- `is_purchased`: whether the put in cart item is purchased, this will be our categorical output.\n",
    "\n",
    "Make sure to de-dup any record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare a dataframe for counting activity in the session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "# first just eliminate the records where event_type = \"view\"\n",
    "\n",
    "cart_purchase_users_all_activity = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we get the number of activities by user session\n",
    "\n",
    "activity_in_session = cart_purchase_users_all_activity.groupby(['user_session'])['event_type'].count().reset_index()\n",
    "activity_in_session = activity_in_session.rename(columns={\"event_type\": \"activity_count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = cart_purchase_users_all_activity.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the event_time to a timestamp\n",
    "\n",
    "df_targets['timestamp'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas.Timestamp.weekday to get the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = df_targets.merge(activity_in_session, on='user_session', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets['activity_count'] = df_targets['activity_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save new data structure for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.to_csv('training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import plot_importance\n",
    "from sklearn.utils import resample\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_purcahase_set = df_targets[df_targets['is_purchased']== 1]\n",
    "is_purcahase_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_purcahase_set = df_targets[df_targets['is_purchased']== 0]\n",
    "not_purcahase_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500000\n",
    "is_purchase_downsampled = resample(is_purcahase_set,\n",
    "                                replace = False, \n",
    "                                n_samples = n_samples,\n",
    "                                random_state = 27)\n",
    "not_purcahase_set_downsampled = resample(not_purcahase_set,\n",
    "                                replace = False,\n",
    "                                n_samples = n_samples,\n",
    "                                random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled = pd.concat([is_purchase_downsampled, not_purcahase_set_downsampled])\n",
    "downsampled['is_purchased'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = downsampled.loc[:,\n",
    "                           ['brand', 'price', 'event_weekday', 'category_code_level1',\n",
    "                            'category_code_level2', 'activity_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.loc[:,'brand'] = LabelEncoder().fit_transform(downsampled.loc[:,'brand'].copy())\n",
    "features.loc[:,'event_weekday'] = LabelEncoder().fit_transform(downsampled.loc[:,'event_weekday'].copy())\n",
    "features.loc[:,'category_level1'] = LabelEncoder().fit_transform(downsampled.loc[:,'category_level1'].copy())\n",
    "features.loc[:,'category_level2'] = LabelEncoder().fit_transform(downsampled.loc[:,'category_level2'].copy())\n",
    "\n",
    "is_purchased = LabelEncoder().fit_transform(downsampled['is_purchased'])\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(features.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    is_purchased, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Choose learning rate of 0.1 on XGBClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(learning_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"fbeta:\",metrics.fbeta_score(y_test, y_pred, average='weighted', beta=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "Show feature importance using plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(model, max_num_features=10, importance_type ='gain')\n",
    "plt.rcParams['figure.figsize'] = (40,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
