{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Network Dynamics: Node Centrality - Lab\n", "\n", "## Introduction\n", "\n", "In this lab, you'll get a chance to practice implementing and interpreting the centrality metrics discussed in the previous lesson by investigating the social network from Game of Thrones!\n", "\n", "## Objectives\n", "You will be able to: \n", "- Compare and calculate degree, closeness, betweenness, and eigenvector centrality measures\n", "- Interpret characteristics of certain nodes based on their centrality metrics  "]}, {"cell_type": "markdown", "metadata": {"collapsed": true}, "source": ["## Character Interaction Graph Data\n", "\n", "A. J. Beveridge and J. Shan created a network from George R. Martin's \"A song of ice and fire\" by extracting relationships between characters of the story. [The dataset is available at Github](https://github.com/mathbeveridge/asoiaf). Relationships between characters were formed every time a character's name appears within 15 words of another character. This was designed as an approximate metric for character's interactions with each other. The results of this simple analysis are quite profound and produce interesting visuals such as this graph:\n", "\n", "<img src=\"images/got.png\" width=800>\n", "\n", "With that, it's your turn to start investigating the most central characters!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import networkx as nx\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "sns.set_style('darkgrid')\n", "%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##  Load the dataset \n", "\n", "Start by loading the dataset as a pandas DataFrame. From this, you'll then create a network representation of the dataset using NetworkX. \n", "\n", "The dataset is stored in the file `'asoiaf-all-edges.csv'`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load edges into dataframes\n", "df = None\n", "\n", "# Print the first five rows\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Create a Graph\n", "\n", "- Instantiate an empty graph \n", "- Iterate through the data and create appropriate edges to the empty graph you instantiated above. Be sure to add the weight to each edge "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create an empty graph instance\n", "G = None\n", "\n", "# Read edge lists into dataframes\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Calculate Degree\n", "\n", "To start the investigation of the most central characters in the books, calculate the degree centrality for each character. Then create a bar graph of the top 10 characters according to degree centrality."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Closeness Centrality\n", "\n", "Repeat the above exercise for the top 10 characters according to closeness centrality."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Betweeness Centrality\n", "\n", "Repeat the process one more time for betweeness centrality."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Putting it All Together\n", "\n", "Great! Now put all of these metrics together along with eigenvector centrality. Combine all four metrics into a single dataframe for each character."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Identifying Key Players\n", "\n", "While centrality can tell us a lot, you've also begun to see how certain individuals may not be the most central characters, but can be pivotal in the flow of information from one community to another. In the previous lesson, such nodes were labeled as 'bridges' acting as the intermediaries between two clusters. Try and identify such characters from this dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Drawing the Graph\n", "\n", "To visualize all of these relationships, draw a graph of the network."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Subsetting the Graph\n", "\n", "As you can see, the above graph is undoubtedly noisy, making it difficult to discern any useful patterns. As such, reset the graph and only add edges whose weight is 75 or greater. From there, redraw the graph. To further help with the display, try using `nx.spring_layout(G)` for the position. To jazz it up, try and recolor those nodes which you identified as bridge or bottleneck nodes to communication."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary \n", "\n", "In this lab, we looked at different centrality measures of the graph data for the ASIOF dataset. We also compared these measures to see how they correlate with each other. We also saw in practice, the difference between taking the weighted centrality measures and how it may effect the results. "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.9"}}, "nbformat": 4, "nbformat_minor": 2}