{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Image Classification - Lab\n", "\n", "## Introduction\n", "\n", "Now that you have a working knowledge of CNNs and have practiced implementing associated techniques in Keras, its time to put all of those skills together. In this lab, you'll work to complete a [Kaggle competition](https://www.kaggle.com/c/dog-breed-identification) on classifying dog breeds.\n", "\n", "\n", "## Objectives\n", "\n", "In this lab you will: \n", "\n", "- Compare and apply multiple techniques for tuning a model using data augmentation and pretrained models  \n", "\n", "## Download and Load the Data\n", "\n", "Start by downloading the data locally and loading it into a Pandas DataFrame. Be forewarned that this dataset is fairly large and it is advisable to close other memory intensive applications.\n", "\n", "The data can be found [here](https://www.kaggle.com/c/dog-breed-identification/data).\n", "\n", "It's easiest if you download the data into this directory on your local computer. From there, be sure to uncompress the folder and subfolders. If you download the data elsewhere, be sure to modify the file path when importing the file below."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# No code per se, but download and decompress the data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Preprocessing\n", "\n", "Now that you've downloaded the data, its time to prepare it for some model building! You'll notice that the current structure provided is not the same as our lovely preprocessed folders that you've been given to date. Instead, you have one large training folder with images and a csv file with labels associated with each of these file types. \n", "\n", "Use this to create a directory substructure for a train-validation-test split as we have done previously. Also recall that you'll also want to use one-hot encoding as you are now presented with a multi-class problem as opposed to simple binary classification."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here; open the labels.csv file stored in the zip file"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["000bec180eb18c7604dcecc8fe0dba07.jpg\r\n", "001513dfcb2ffafc82cccf4d8bbaba97.jpg\r\n", "001cdf01b096e06d78e9e5112d419397.jpg\r\n", "00214f311d5d2247d5dfe4fe24b2303d.jpg\r\n", "0021f9ceb3235effd7fcde7f7538ed62.jpg\r\n"]}], "source": ["ls dog_breeds/train/ | head -5"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "In order to input the data into our standard pipeline, you'll need to organize the image files into a nested folder structure. At the top level will be a folder for the training data, a folder for the validation data, and a folder for the test data. Within these top directory folders, you'll then need to create a folder for each of the categorical classes (in this case, dog breeds). Finally, within these category folders you'll then place each of the associated image files. To save time, do this for just 3 of the dog breeds such as `'boston_bull'`, `'toy_poodle'`, and `'scottish_deerhound'`.\n", "\n", "You're nested file structure should look like this:\n", "* train\n", "    * category_1\n", "    * category_2\n", "    * category_3\n", "    ...\n", "* val\n", "    * category_1\n", "    * category_2\n", "    * category_3\n", "    ...\n", "* test \n", "    * category_1\n", "    * category_2\n", "    * category_3\n", "    ...  \n", "\n", "> **Hint**: To do this, you can use the `os` module which will you can use to execute many common bash commands straight from your python interpreter. For example, here's how you could make a new folder: \n", "\n", "```python\n", "import os\n", "os.mkdir('New_Folder_Name')\n", "```\n", "Start by creating top level folders for the train, validation, and test sets. Then, use your pandas DataFrame to split the example images for each breed of dog into a 80% train set, and 10% validation and test sets. Use `os.path.join()` with the information from the DataFrame to construct the relevant file path. With this, place the relevant images using the `shutil.copy()` into the appropriate directory. \n", "\n", ">> **Note**: It is worthwhile to try this exercise on your own, but you can also use the images stored under the `'data_org_subset/'` folder of this repository, in which the Kaggle dataset has already been subset and preprocessed."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here; transform the image files and then load them into Keras as tensors \n", "# (be sure to perform a train-val-test split)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Optional: Build a Baseline CNN\n", "\n", "This is an optional step. Adapting a pretrained model will produce better results, but it may be interesting to create a CNN from scratch as a baseline. If you wish to, do so here."]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["# Create a baseline CNN model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Loading a Pretrained CNN\n", "\n", "## Feature Engineering with the Pretrained Model\n", "\n", "As you may well have guessed, adapting a pretrained model will undoubtedly produce better results then a fresh CNN due to the limited size of training data. Import a pretrained model such as VGG-19 to use a convolutional base. Use this to transform the dataset into a rich feature space and add a few fully connected layers on top of the pretrained layers to build a classification model. (Be sure to leave the pretrained model frozen!)"]}, {"cell_type": "code", "execution_count": 61, "metadata": {}, "outputs": [], "source": ["# Your code here; add fully connected layers on top of the convolutional base"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Visualize History\n", "\n", "Now fit the model and visualize the training and validation accuracy/loss functions over successive epochs."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here; visualize the training / validation history associated with fitting the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Save model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Final Model Evaluation\n", "\n", "Now that you've trained and validated the model, perform a final evaluation of the model on the test set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "\n", "Congratulations! In this lab, you brought all of your prior deep learning skills together from preprocessing including one-hot encoding, to adapting a pretrained model. There are always ongoing advancements in CNN architectures and best practices, but you have a solid foundation and understanding at this point."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 2}